{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3ca887d7-925a-43d5-bb80-30e94595bedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "tensor(-0.4940, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.4997, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5019, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5002, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5031, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5052, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5077, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5164, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5220, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5170, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5117, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5285, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5113, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5382, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5448, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5192, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5110, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5449, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5595, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5245, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5094, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5360, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5619, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5283, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.4830, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5530, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5331, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5298, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5493, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5875, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5729, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5177, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5344, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5527, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5903, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5608, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5809, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5349, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5598, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5392, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5226, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.4887, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5685, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5371, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5501, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6016, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6036, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5326, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5800, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5556, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5438, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5472, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6141, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5647, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5374, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5242, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5303, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5265, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5624, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6052, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5556, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.4892, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5474, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5717, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5407, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5270, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5325, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5622, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5158, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5626, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5731, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5601, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5796, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5897, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5677, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5429, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5607, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5815, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5819, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5734, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5639, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6099, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5402, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5510, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5252, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5757, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5480, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5662, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5780, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6016, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5843, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6078, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6076, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5906, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5746, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6086, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5697, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5850, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5583, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5513, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5735, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5851, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5792, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6082, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5357, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5821, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5842, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5642, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6171, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6133, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5843, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5803, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6017, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5876, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6035, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6129, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6126, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6108, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5633, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5581, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6166, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6021, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6043, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5819, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5667, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5730, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5893, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6235, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6245, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6262, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6490, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6165, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6010, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5955, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6230, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6070, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5953, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5775, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6031, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6565, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6516, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6152, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6495, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6241, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.5932, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6120, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6597, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6342, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6315, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6214, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6340, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6316, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6234, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6371, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6622, grad_fn=<NllLossBackward0>)\n",
      "tensor(-0.6366, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x768 and 3072x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imgBatch,labelTensor \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     43\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 44\u001b[0m     trialOutput \u001b[38;5;241m=\u001b[39m model(imgBatch\u001b[38;5;241m.\u001b[39mview(batchSize,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     45\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(trialOutput,labelTensor)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\anacondaReal\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\anacondaReal\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\anacondaReal\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\anacondaReal\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\anacondaReal\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\anacondaReal\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x768 and 3072x512)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True,transform=transforms.ToTensor())\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True,transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))]))\n",
    "\n",
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "    for img, label in cifar10\n",
    "    if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "    for img, label in cifar10_val\n",
    "    if label in [0, 2]]\n",
    "\n",
    "#Get a sample data point, figure out its number of elements when we put it in 1D\n",
    "img,_ = cifar2[0]\n",
    "inputSize = img.view(-1).size(dim=0)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(inputSize,512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512,2),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "#Hyperparameters\n",
    "learning_rate = 0.01\n",
    "loss_fn = nn.NLLLoss()\n",
    "num_epochs = 500\n",
    "batchSize = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2,batch_size=batchSize,shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for imgBatch,labelTensor in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        trialOutput = model(imgBatch.view(batchSize,-1))\n",
    "        loss = loss_fn(trialOutput,labelTensor)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2092cbc1-3330-4596-8552-d019acc06056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 0, Loss: -0.605141\n",
      "Epoch: 1, Loss: -0.681741\n",
      "Epoch: 2, Loss: -0.685748\n",
      "Epoch: 3, Loss: -0.756493\n",
      "Epoch: 4, Loss: -0.781397\n",
      "Epoch: 5, Loss: -0.771859\n",
      "Epoch: 6, Loss: -0.825474\n",
      "Epoch: 7, Loss: -0.851723\n",
      "Epoch: 8, Loss: -0.803680\n",
      "Epoch: 9, Loss: -0.759217\n",
      "Epoch: 10, Loss: -0.722692\n",
      "Epoch: 11, Loss: -0.835863\n",
      "Epoch: 12, Loss: -0.744093\n",
      "Epoch: 13, Loss: -0.647522\n",
      "Epoch: 14, Loss: -0.585038\n",
      "Epoch: 15, Loss: -0.738559\n",
      "Epoch: 16, Loss: -0.805017\n",
      "Epoch: 17, Loss: -0.691892\n",
      "Epoch: 18, Loss: -0.839861\n",
      "Epoch: 19, Loss: -0.747814\n",
      "Epoch: 20, Loss: -0.787520\n",
      "Epoch: 21, Loss: -0.858551\n",
      "Epoch: 22, Loss: -0.601977\n",
      "Epoch: 23, Loss: -0.690486\n",
      "Epoch: 24, Loss: -0.925747\n",
      "Epoch: 25, Loss: -0.834208\n",
      "Epoch: 26, Loss: -0.690135\n",
      "Epoch: 27, Loss: -0.808483\n",
      "Epoch: 28, Loss: -0.682485\n",
      "Epoch: 29, Loss: -0.870287\n",
      "Epoch: 30, Loss: -0.814981\n",
      "Epoch: 31, Loss: -0.790291\n",
      "Epoch: 32, Loss: -0.853396\n",
      "Epoch: 33, Loss: -0.697803\n",
      "Epoch: 34, Loss: -0.813371\n",
      "Epoch: 35, Loss: -0.870701\n",
      "Epoch: 36, Loss: -0.882980\n",
      "Epoch: 37, Loss: -0.849689\n",
      "Epoch: 38, Loss: -0.689944\n",
      "Epoch: 39, Loss: -0.648817\n",
      "Epoch: 40, Loss: -0.713880\n",
      "Epoch: 41, Loss: -0.720629\n",
      "Epoch: 42, Loss: -0.913643\n",
      "Epoch: 43, Loss: -0.847329\n",
      "Epoch: 44, Loss: -0.854297\n",
      "Epoch: 45, Loss: -0.814547\n",
      "Epoch: 46, Loss: -0.889360\n",
      "Epoch: 47, Loss: -0.732553\n",
      "Epoch: 48, Loss: -0.769818\n",
      "Epoch: 49, Loss: -0.667020\n",
      "Epoch: 50, Loss: -0.639160\n",
      "Epoch: 51, Loss: -0.938326\n",
      "Epoch: 52, Loss: -0.809857\n",
      "Epoch: 53, Loss: -0.813407\n",
      "Epoch: 54, Loss: -0.691710\n",
      "Epoch: 55, Loss: -0.898318\n",
      "Epoch: 56, Loss: -0.680447\n",
      "Epoch: 57, Loss: -0.877062\n",
      "Epoch: 58, Loss: -0.660349\n",
      "Epoch: 59, Loss: -0.960316\n",
      "Epoch: 60, Loss: -0.869873\n",
      "Epoch: 61, Loss: -0.739382\n",
      "Epoch: 62, Loss: -0.643628\n",
      "Epoch: 63, Loss: -0.826156\n",
      "Epoch: 64, Loss: -0.964899\n",
      "Epoch: 65, Loss: -0.884761\n",
      "Epoch: 66, Loss: -0.751063\n",
      "Epoch: 67, Loss: -0.803668\n",
      "Epoch: 68, Loss: -0.882438\n",
      "Epoch: 69, Loss: -0.811154\n",
      "Epoch: 70, Loss: -0.978786\n",
      "Epoch: 71, Loss: -0.664692\n",
      "Epoch: 72, Loss: -0.840936\n",
      "Epoch: 73, Loss: -0.781280\n",
      "Epoch: 74, Loss: -0.710105\n",
      "Epoch: 75, Loss: -0.824248\n",
      "Epoch: 76, Loss: -0.771343\n",
      "Epoch: 77, Loss: -0.913720\n",
      "Epoch: 78, Loss: -0.672823\n",
      "Epoch: 79, Loss: -0.977493\n",
      "Epoch: 80, Loss: -0.738741\n",
      "Epoch: 81, Loss: -0.932560\n",
      "Epoch: 82, Loss: -0.754452\n",
      "Epoch: 83, Loss: -0.792032\n",
      "Epoch: 84, Loss: -0.785525\n",
      "Epoch: 85, Loss: -0.877943\n",
      "Epoch: 86, Loss: -0.802446\n",
      "Epoch: 87, Loss: -0.809982\n",
      "Epoch: 88, Loss: -0.865317\n",
      "Epoch: 89, Loss: -0.892704\n",
      "Epoch: 90, Loss: -0.726280\n",
      "Epoch: 91, Loss: -0.860668\n",
      "Epoch: 92, Loss: -0.775730\n",
      "Epoch: 93, Loss: -0.833097\n",
      "Epoch: 94, Loss: -0.927331\n",
      "Epoch: 95, Loss: -0.759176\n",
      "Epoch: 96, Loss: -0.718608\n",
      "Epoch: 97, Loss: -0.842759\n",
      "Epoch: 98, Loss: -0.796679\n",
      "Epoch: 99, Loss: -0.811032\n",
      "Epoch: 100, Loss: -0.868885\n",
      "Epoch: 101, Loss: -0.677871\n",
      "Epoch: 102, Loss: -0.865810\n",
      "Epoch: 103, Loss: -0.730180\n",
      "Epoch: 104, Loss: -0.846404\n",
      "Epoch: 105, Loss: -0.708826\n",
      "Epoch: 106, Loss: -0.881757\n",
      "Epoch: 107, Loss: -0.927485\n",
      "Epoch: 108, Loss: -0.804931\n",
      "Epoch: 109, Loss: -0.797098\n",
      "Epoch: 110, Loss: -0.781317\n",
      "Epoch: 111, Loss: -0.755115\n",
      "Epoch: 112, Loss: -0.824086\n",
      "Epoch: 113, Loss: -0.693985\n",
      "Epoch: 114, Loss: -0.859610\n",
      "Epoch: 115, Loss: -0.791550\n",
      "Epoch: 116, Loss: -0.857816\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imgs,labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     43\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 44\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(imgs\u001b[38;5;241m.\u001b[39mview(batch_size,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     45\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs,labels)\n\u001b[0;32m     47\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\anacondaReal\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\anacondaReal\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\anacondaReal\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\anacondaReal\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\anacondaReal\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\anacondaReal\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True,transform=transforms.ToTensor())\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True,transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))]))\n",
    "\n",
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "    for img, label in cifar10\n",
    "    if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "    for img, label in cifar10_val\n",
    "    if label in [0, 2]]\n",
    "\n",
    "#Get a sample data point, figure out its number of elements when we put it in 1D\n",
    "img,_ = cifar2[0]\n",
    "inputSize = img.view(-1).size(dim=0)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(inputSize,512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512,2),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "#Hyperparameters\n",
    "learning_rate = 0.01\n",
    "loss_fn = nn.NLLLoss()\n",
    "num_epochs = 500\n",
    "batchSize = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2,batch_size=batchSize,shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for imgs,labels in train_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size,-1))\n",
    "        loss = loss_fn(outputs,labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5bbeebf9-0195-4227-a6ba-e799549d325d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 0, Loss: -0.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs,torch\u001b[38;5;241m.\u001b[39mtensor([label]))\n\u001b[0;32m     46\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 47\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     48\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch, \u001b[38;5;28mfloat\u001b[39m(loss)))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\anacondaReal\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    527\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\anacondaReal\\Lib\\site-packages\\torch\\autograd\\__init__.py:260\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    251\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    252\u001b[0m     (inputs,)\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (torch\u001b[38;5;241m.\u001b[39mTensor, graph\u001b[38;5;241m.\u001b[39mGradientEdge))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[0;32m    257\u001b[0m )\n\u001b[0;32m    259\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[1;32m--> 260\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _make_grads(tensors, grad_tensors_, is_grads_batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\anacondaReal\\Lib\\site-packages\\torch\\autograd\\__init__.py:143\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[0;32m    137\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    138\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m         )\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[0;32m    142\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 143\u001b[0m         torch\u001b[38;5;241m.\u001b[39mones_like(out, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format)\n\u001b[0;32m    144\u001b[0m     )\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True,transform=transforms.ToTensor())\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True,transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))]))\n",
    "\n",
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "    for img, label in cifar10\n",
    "    if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "    for img, label in cifar10_val\n",
    "    if label in [0, 2]]\n",
    "\n",
    "#Get a sample data point, figure out its number of elements when we put it in 1D\n",
    "img,_ = cifar2[0]\n",
    "inputSize = img.view(-1).size(dim=0)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(inputSize,512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512,2),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "#Hyperparameters\n",
    "learning_rate = 0.01\n",
    "loss_fn = nn.NLLLoss()\n",
    "num_epochs = 500\n",
    "batchSize = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2,batch_size=batchSize,shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for imgs,label in cifar2:\n",
    "        outputs = model(imgs.view(-1).unsqueeze(0))\n",
    "        loss = loss_fn(outputs,torch.tensor([label]))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9893e01-f7ed-435d-81f1-36b8157b869b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
